{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system? True\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/kuangliu/pytorch-cifar/issues/19\n",
    "test_t = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "    ]\n",
    ")\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        test_t\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "test_data  = torchvision.datasets.CIFAR10(\n",
    "    root='./data', \n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=test_t\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=48, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=48, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, channel_in, pass_on, channel_out, device):\n",
    "        super().__init__()\n",
    "        self.conv_1x1 = nn.Sequential(\n",
    "            nn.Conv2d(channel_in, channel_out[\"1x1\"], kernel_size=1),\n",
    "            nn.BatchNorm2d(channel_out[\"1x1\"]),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "    \n",
    "        # 3x3 branch, we padding 1 in the 3x3 convolution layer to keep same size of image\n",
    "        self.conv_3x3 = nn.Sequential(\n",
    "            nn.Conv2d(channel_in, pass_on[\"3x3\"], kernel_size=1),\n",
    "            nn.BatchNorm2d(pass_on[\"3x3\"]),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(pass_on[\"3x3\"], channel_out[\"3x3\"], kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(channel_out[\"3x3\"]),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        # 5x5 branch, we padding 2 in the 5x5 convolution layer to keep same size of image\n",
    "        self.conv_5x5 = nn.Sequential(\n",
    "            nn.Conv2d(channel_in, pass_on[\"5x5\"], kernel_size=1),\n",
    "            nn.BatchNorm2d(pass_on[\"5x5\"]),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(pass_on[\"5x5\"], channel_out[\"5x5\"], kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(channel_out[\"5x5\"]),\n",
    "            nn.PReLU()\n",
    "        ) \n",
    "        # Max pooling branch\n",
    "        self.max_pool = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1),\n",
    "            nn.Conv2d(channel_in, channel_out[\"max\"], kernel_size=1),\n",
    "            nn.BatchNorm2d(channel_out[\"max\"]),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat(\n",
    "            [\n",
    "                self.conv_1x1(x), self.conv_3x3(x),\n",
    "                self.conv_5x5(x), self.max_pool(x)\n",
    "            ], dim=1 # concatenate along channels\n",
    "        )\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.1)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/1502.01852.pdf\n",
    "# https://arxiv.org/pdf/1409.4842.pdf\n",
    "\n",
    "class CifarGoogle(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels=3, \n",
    "                 n_classes=10,\n",
    "                 device='cpu', \n",
    "                 lr=0.01):\n",
    "        super(CifarGoogle, self).__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            # input layer\n",
    "            nn.Conv2d(3, 64, kernel_size=7, padding=3),\n",
    "            nn.PReLU(),\n",
    "            nn.LocalResponseNorm(128),\n",
    "            nn.Conv2d(64, 112, kernel_size=1),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(112, 196, kernel_size=3, padding=1),\n",
    "            nn.PReLU(),\n",
    "            nn.LocalResponseNorm(128),\n",
    "            # pass through blocks\n",
    "            Block(\n",
    "                196, \n",
    "                pass_on={\"3x3\": 96, \"5x5\": 16}, \n",
    "                channel_out={\"1x1\": 64, \"3x3\": 128, \"5x5\": 32, \"max\": 32},\n",
    "                device=device\n",
    "            ),\n",
    "            Block(\n",
    "                256, \n",
    "                pass_on={\"3x3\": 128, \"5x5\": 32}, \n",
    "                channel_out={\"1x1\": 128, \"3x3\": 192, \"5x5\": 96, \"max\": 64},\n",
    "                device=device\n",
    "            ),\n",
    "            # reduce dimensions\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),  \n",
    "            # pass through blocks\n",
    "            Block(\n",
    "                480, \n",
    "                pass_on={\"3x3\": 96, \"5x5\": 16}, \n",
    "                channel_out={\"1x1\": 192, \"3x3\": 208, \"5x5\": 48, \"max\": 64}, \n",
    "                device=device\n",
    "            ),\n",
    "            Block(\n",
    "                512, \n",
    "                pass_on={\"3x3\": 112, \"5x5\": 24}, \n",
    "                channel_out={\"1x1\": 160, \"3x3\": 224, \"5x5\": 64, \"max\": 64}, \n",
    "                device=device\n",
    "            ),\n",
    "            Block(\n",
    "                512, \n",
    "                pass_on={\"3x3\": 128, \"5x5\": 24}, \n",
    "                channel_out={\"1x1\": 128, \"3x3\": 256, \"5x5\": 64, \"max\": 64}, \n",
    "                device=device\n",
    "            ),\n",
    "            Block(\n",
    "                512, \n",
    "                pass_on={\"3x3\": 112, \"5x5\": 32}, \n",
    "                channel_out={\"1x1\": 112, \"3x3\": 288, \"5x5\": 64, \"max\": 64}, \n",
    "                device=device\n",
    "            ),\n",
    "            # reduce dimensions\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),\n",
    "            # pass through last blocks\n",
    "            Block(\n",
    "                528, \n",
    "                pass_on={\"3x3\": 160, \"5x5\": 32}, \n",
    "                channel_out={\"1x1\": 256, \"3x3\": 320, \"5x5\": 128, \"max\": 128},\n",
    "                device=device\n",
    "            ),\n",
    "            Block(\n",
    "                832, \n",
    "                pass_on={\"3x3\": 150, \"5x5\": 42}, \n",
    "                channel_out={\"1x1\": 266, \"3x3\": 330, \"5x5\": 108, \"max\": 128},\n",
    "                device=device\n",
    "            ),\n",
    "            # pool\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            # classification head\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(832, 10),\n",
    "            nn.Softmax(1)\n",
    "        )\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        self.criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        self.device = device\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.total_epochs_trained = 0\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "    def train(self, train_loader, test_loader, train_epochs):\n",
    "        break_count = 0\n",
    "        max_break_count = 15\n",
    "        max_test_acc = -9e15\n",
    "        epoch_train_loss = epoch_test_loss = 0\n",
    "        epoch_train_losses = []\n",
    "        epoch_test_losses = []\n",
    "\n",
    "        state_dict = None\n",
    "\n",
    "        for epoch in range(train_epochs):\n",
    "            total_train_loss = total_test_acc = 0\n",
    "            for image,label in train_loader:\n",
    "                image = image.to(self.device)\n",
    "                label = label.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                preds = self.forward(image)\n",
    "\n",
    "                loss = self.criterion(preds, label)\n",
    "                total_train_loss += loss.item()\n",
    "                loss.backward()\n",
    "\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                self.training = False\n",
    "                for module in self.children():\n",
    "                    module.train(False)\n",
    "                \n",
    "                for image,label in test_loader:\n",
    "                    image = image.to(self.device)\n",
    "                    label = label.to(self.device)\n",
    "\n",
    "                    preds = self.forward(image)\n",
    "\n",
    "                    total_test_acc += (\n",
    "                        torch.sum(torch.argmax(preds, dim=1) == label).item()\n",
    "                    )\n",
    "                    \n",
    "                self.training = True\n",
    "                for module in self.children():\n",
    "                    module.train(True)\n",
    "\n",
    "            total_test_acc /= test_loader.dataset.data.shape[0]\n",
    "\n",
    "            self.total_epochs_trained += 1\n",
    "\n",
    "            print(f'''[Epoch {epoch} / Global Epoch {self.total_epochs_trained}]''')\n",
    "            print(f'''    Train Loss:     {total_train_loss}''')\n",
    "            print(f'''    Test Accuracy:  {total_test_acc}''')\n",
    "\n",
    "            if (total_test_acc > max_test_acc):\n",
    "                max_test_acc = total_test_acc\n",
    "                state_dict = copy.deepcopy(self.state_dict())\n",
    "                break_count = 0\n",
    "            else:\n",
    "                break_count += 1\n",
    "                if break_count >= max_break_count:\n",
    "                    print(\"Stopping Early.\")\n",
    "                    self.load_state_dict(state_dict)\n",
    "                    break\n",
    "\n",
    "            print(f'''    Best Test Acc:  {max_test_acc}\\n''')\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybing = CifarGoogle(\n",
    "    in_channels=3, \n",
    "    n_classes=10,\n",
    "    device=DEVICE,\n",
    "    lr=0.0001\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / Global Epoch 1]\n",
      "    Train Loss:     2126.458132624626\n",
      "    Test Accuracy:  0.4889\n",
      "    Best Test Acc:  0.4889\n",
      "\n",
      "[Epoch 1 / Global Epoch 2]\n",
      "    Train Loss:     1978.6962685585022\n",
      "    Test Accuracy:  0.591\n",
      "    Best Test Acc:  0.591\n",
      "\n",
      "[Epoch 2 / Global Epoch 3]\n",
      "    Train Loss:     1909.254210114479\n",
      "    Test Accuracy:  0.638\n",
      "    Best Test Acc:  0.638\n",
      "\n",
      "[Epoch 3 / Global Epoch 4]\n",
      "    Train Loss:     1854.7839585542679\n",
      "    Test Accuracy:  0.6953\n",
      "    Best Test Acc:  0.6953\n",
      "\n",
      "[Epoch 4 / Global Epoch 5]\n",
      "    Train Loss:     1816.6994429826736\n",
      "    Test Accuracy:  0.7044\n",
      "    Best Test Acc:  0.7044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(f\"model_large_{mybing.total_epochs_trained}.pt\", \"w\").close()\n",
    "torch.save({\n",
    "    'model_state': mybing.state_dict(),\n",
    "    'optimizer_state': mybing.optimizer.state_dict(),\n",
    "    'epoch': mybing.total_epochs_trained\n",
    "    }, f\"model_large_{mybing.total_epochs_trained}.pt\"\n",
    ")\n",
    "\n",
    "mybing.train(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    5\n",
    ")\n",
    "\n",
    "f = open(f\"model_large_{mybing.total_epochs_trained}.pt\", \"w\").close()\n",
    "torch.save({\n",
    "    'model_state': mybing.state_dict(),\n",
    "    'optimizer_state': mybing.optimizer.state_dict(),\n",
    "    'epoch': mybing.total_epochs_trained\n",
    "    }, f\"model_large_{mybing.total_epochs_trained}.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_large_5.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybing.load_state_dict(checkpoint['model_state'])\n",
    "mybing.optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "mybing.total_epochs_trained = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / Global Epoch 6]\n",
      "    Train Loss:     1790.1647598743439\n",
      "    Test Accuracy:  0.7354\n",
      "    Best Test Acc:  0.7354\n",
      "\n",
      "[Epoch 1 / Global Epoch 7]\n",
      "    Train Loss:     1769.217351436615\n",
      "    Test Accuracy:  0.7563\n",
      "    Best Test Acc:  0.7563\n",
      "\n",
      "[Epoch 2 / Global Epoch 8]\n",
      "    Train Loss:     1751.1587373018265\n",
      "    Test Accuracy:  0.7698\n",
      "    Best Test Acc:  0.7698\n",
      "\n",
      "[Epoch 3 / Global Epoch 9]\n",
      "    Train Loss:     1737.7428050041199\n",
      "    Test Accuracy:  0.7795\n",
      "    Best Test Acc:  0.7795\n",
      "\n",
      "[Epoch 4 / Global Epoch 10]\n",
      "    Train Loss:     1724.7332781553268\n",
      "    Test Accuracy:  0.786\n",
      "    Best Test Acc:  0.786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mybing.train(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    5\n",
    ")\n",
    "\n",
    "f = open(f\"model_large_{mybing.total_epochs_trained}.pt\", \"w\").close()\n",
    "torch.save({\n",
    "    'model_state': mybing.state_dict(),\n",
    "    'optimizer_state': mybing.optimizer.state_dict(),\n",
    "    'epoch': mybing.total_epochs_trained\n",
    "    }, f\"model_large_{mybing.total_epochs_trained}.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint2 = torch.load(\"model_large_10.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybing.load_state_dict(checkpoint2['model_state'])\n",
    "mybing.optimizer.load_state_dict(checkpoint2['optimizer_state'])\n",
    "mybing.total_epochs_trained = checkpoint2['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(mybing.total_epochs_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / Global Epoch 11]\n",
      "    Train Loss:     1716.1553529500961\n",
      "    Test Accuracy:  0.7942\n",
      "    Best Test Acc:  0.7942\n",
      "\n",
      "[Epoch 1 / Global Epoch 12]\n",
      "    Train Loss:     1702.9403219223022\n",
      "    Test Accuracy:  0.7812\n",
      "    Best Test Acc:  0.7942\n",
      "\n",
      "[Epoch 2 / Global Epoch 13]\n",
      "    Train Loss:     1694.8358651399612\n",
      "    Test Accuracy:  0.8068\n",
      "    Best Test Acc:  0.8068\n",
      "\n",
      "[Epoch 3 / Global Epoch 14]\n",
      "    Train Loss:     1687.8354079723358\n",
      "    Test Accuracy:  0.8054\n",
      "    Best Test Acc:  0.8068\n",
      "\n",
      "[Epoch 4 / Global Epoch 15]\n",
      "    Train Loss:     1678.9988315105438\n",
      "    Test Accuracy:  0.8165\n",
      "    Best Test Acc:  0.8165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mybing.train(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    5\n",
    ")\n",
    "\n",
    "f = open(f\"model_large_{mybing.total_epochs_trained}.pt\", \"w\").close()\n",
    "torch.save({\n",
    "    'model_state': mybing.state_dict(),\n",
    "    'optimizer_state': mybing.optimizer.state_dict(),\n",
    "    'epoch': mybing.total_epochs_trained\n",
    "    }, f\"model_large_{mybing.total_epochs_trained}.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint3 = torch.load(\"model_large_15.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "mybing.load_state_dict(checkpoint3['model_state'])\n",
    "mybing.optimizer.load_state_dict(checkpoint3['optimizer_state'])\n",
    "mybing.total_epochs_trained = checkpoint3['epoch']\n",
    "\n",
    "print(mybing.total_epochs_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / Global Epoch 16]\n",
      "    Train Loss:     1672.5715950727463\n",
      "    Test Accuracy:  0.8227\n",
      "    Best Test Acc:  0.8227\n",
      "\n",
      "[Epoch 1 / Global Epoch 17]\n",
      "    Train Loss:     1665.5884673595428\n",
      "    Test Accuracy:  0.8175\n",
      "    Best Test Acc:  0.8227\n",
      "\n",
      "[Epoch 2 / Global Epoch 18]\n",
      "    Train Loss:     1660.4399118423462\n",
      "    Test Accuracy:  0.8319\n",
      "    Best Test Acc:  0.8319\n",
      "\n",
      "[Epoch 3 / Global Epoch 19]\n",
      "    Train Loss:     1653.895160317421\n",
      "    Test Accuracy:  0.8321\n",
      "    Best Test Acc:  0.8321\n",
      "\n",
      "[Epoch 4 / Global Epoch 20]\n",
      "    Train Loss:     1649.6739035844803\n",
      "    Test Accuracy:  0.8337\n",
      "    Best Test Acc:  0.8337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mybing.train(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    5\n",
    ")\n",
    "\n",
    "f = open(f\"model_large_{mybing.total_epochs_trained}.pt\", \"w\").close()\n",
    "torch.save({\n",
    "    'model_state': mybing.state_dict(),\n",
    "    'optimizer_state': mybing.optimizer.state_dict(),\n",
    "    'epoch': mybing.total_epochs_trained\n",
    "    }, f\"model_large_{mybing.total_epochs_trained}.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint4 = torch.load(\"model_large_20.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "mybing.load_state_dict(checkpoint4['model_state'])\n",
    "mybing.optimizer.load_state_dict(checkpoint4['optimizer_state'])\n",
    "mybing.total_epochs_trained = checkpoint4['epoch']\n",
    "\n",
    "print(mybing.total_epochs_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / Global Epoch 21]\n",
      "    Train Loss:     1647.5573140382767\n",
      "    Test Accuracy:  0.8551\n",
      "    Best Test Acc:  0.8551\n",
      "\n",
      "[Epoch 1 / Global Epoch 22]\n",
      "    Train Loss:     1641.3319432735443\n",
      "    Test Accuracy:  0.8532\n",
      "    Best Test Acc:  0.8551\n",
      "\n",
      "[Epoch 2 / Global Epoch 23]\n",
      "    Train Loss:     1638.7560341358185\n",
      "    Test Accuracy:  0.8612\n",
      "    Best Test Acc:  0.8612\n",
      "\n",
      "[Epoch 3 / Global Epoch 24]\n",
      "    Train Loss:     1632.1314253807068\n",
      "    Test Accuracy:  0.8586\n",
      "    Best Test Acc:  0.8612\n",
      "\n",
      "[Epoch 4 / Global Epoch 25]\n",
      "    Train Loss:     1628.480310678482\n",
      "    Test Accuracy:  0.8668\n",
      "    Best Test Acc:  0.8668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mybing.train(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    5\n",
    ")\n",
    "\n",
    "f = open(f\"model_large_{mybing.total_epochs_trained}.pt\", \"w\").close()\n",
    "torch.save({\n",
    "    'model_state': mybing.state_dict(),\n",
    "    'optimizer_state': mybing.optimizer.state_dict(),\n",
    "    'epoch': mybing.total_epochs_trained\n",
    "    }, f\"model_large_{mybing.total_epochs_trained}.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint5 = torch.load(\"model_large_25.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "mybing.load_state_dict(checkpoint5['model_state'])\n",
    "mybing.optimizer.load_state_dict(checkpoint5['optimizer_state'])\n",
    "mybing.total_epochs_trained = checkpoint5['epoch']\n",
    "\n",
    "print(mybing.total_epochs_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / Global Epoch 26]\n",
      "    Train Loss:     1624.3030341863632\n",
      "    Test Accuracy:  0.8676\n",
      "    Best Test Acc:  0.8676\n",
      "\n",
      "[Epoch 1 / Global Epoch 27]\n",
      "    Train Loss:     1621.163398385048\n",
      "    Test Accuracy:  0.8626\n",
      "    Best Test Acc:  0.8676\n",
      "\n",
      "[Epoch 2 / Global Epoch 28]\n",
      "    Train Loss:     1619.2955071926117\n",
      "    Test Accuracy:  0.8658\n",
      "    Best Test Acc:  0.8676\n",
      "\n",
      "[Epoch 3 / Global Epoch 29]\n",
      "    Train Loss:     1616.646876692772\n",
      "    Test Accuracy:  0.8756\n",
      "    Best Test Acc:  0.8756\n",
      "\n",
      "[Epoch 4 / Global Epoch 30]\n",
      "    Train Loss:     1613.7162551879883\n",
      "    Test Accuracy:  0.875\n",
      "    Best Test Acc:  0.8756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mybing.train(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    5\n",
    ")\n",
    "\n",
    "f = open(f\"model_large_{mybing.total_epochs_trained}.pt\", \"w\").close()\n",
    "torch.save({\n",
    "    'model_state': mybing.state_dict(),\n",
    "    'optimizer_state': mybing.optimizer.state_dict(),\n",
    "    'epoch': mybing.total_epochs_trained\n",
    "    }, f\"model_large_{mybing.total_epochs_trained}.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint6 = torch.load(\"model_large_30.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "mybing.load_state_dict(checkpoint6['model_state'])\n",
    "mybing.optimizer.load_state_dict(checkpoint6['optimizer_state'])\n",
    "mybing.total_epochs_trained = checkpoint6['epoch']\n",
    "\n",
    "print(mybing.total_epochs_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / Global Epoch 31]\n",
      "    Train Loss:     1611.0862920284271\n",
      "    Test Accuracy:  0.8699\n",
      "    Best Test Acc:  0.8699\n",
      "\n",
      "[Epoch 1 / Global Epoch 32]\n",
      "    Train Loss:     1609.408675789833\n",
      "    Test Accuracy:  0.8734\n",
      "    Best Test Acc:  0.8734\n",
      "\n",
      "[Epoch 2 / Global Epoch 33]\n",
      "    Train Loss:     1604.6497066020966\n",
      "    Test Accuracy:  0.8783\n",
      "    Best Test Acc:  0.8783\n",
      "\n",
      "[Epoch 3 / Global Epoch 34]\n",
      "    Train Loss:     1602.7326176166534\n",
      "    Test Accuracy:  0.8683\n",
      "    Best Test Acc:  0.8783\n",
      "\n",
      "[Epoch 4 / Global Epoch 35]\n",
      "    Train Loss:     1601.099912762642\n",
      "    Test Accuracy:  0.8801\n",
      "    Best Test Acc:  0.8801\n",
      "\n",
      "[Epoch 5 / Global Epoch 36]\n",
      "    Train Loss:     1598.07659471035\n",
      "    Test Accuracy:  0.8773\n",
      "    Best Test Acc:  0.8801\n",
      "\n",
      "[Epoch 6 / Global Epoch 37]\n",
      "    Train Loss:     1596.1671664714813\n",
      "    Test Accuracy:  0.8786\n",
      "    Best Test Acc:  0.8801\n",
      "\n",
      "[Epoch 7 / Global Epoch 38]\n",
      "    Train Loss:     1595.1360617876053\n",
      "    Test Accuracy:  0.8793\n",
      "    Best Test Acc:  0.8801\n",
      "\n",
      "[Epoch 8 / Global Epoch 39]\n",
      "    Train Loss:     1594.4578816890717\n",
      "    Test Accuracy:  0.8832\n",
      "    Best Test Acc:  0.8832\n",
      "\n",
      "[Epoch 9 / Global Epoch 40]\n",
      "    Train Loss:     1590.8183085918427\n",
      "    Test Accuracy:  0.8778\n",
      "    Best Test Acc:  0.8832\n",
      "\n",
      "[Epoch 10 / Global Epoch 41]\n",
      "    Train Loss:     1590.0119434595108\n",
      "    Test Accuracy:  0.8783\n",
      "    Best Test Acc:  0.8832\n",
      "\n",
      "[Epoch 11 / Global Epoch 42]\n",
      "    Train Loss:     1587.8845998048782\n",
      "    Test Accuracy:  0.8835\n",
      "    Best Test Acc:  0.8835\n",
      "\n",
      "[Epoch 12 / Global Epoch 43]\n",
      "    Train Loss:     1586.0288021564484\n",
      "    Test Accuracy:  0.8832\n",
      "    Best Test Acc:  0.8835\n",
      "\n",
      "[Epoch 13 / Global Epoch 44]\n",
      "    Train Loss:     1585.4707671403885\n",
      "    Test Accuracy:  0.8815\n",
      "    Best Test Acc:  0.8835\n",
      "\n",
      "[Epoch 14 / Global Epoch 45]\n",
      "    Train Loss:     1581.4918109178543\n",
      "    Test Accuracy:  0.8851\n",
      "    Best Test Acc:  0.8851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mybing.train(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    15\n",
    ")\n",
    "\n",
    "f = open(f\"model_large_{mybing.total_epochs_trained}.pt\", \"w\").close()\n",
    "torch.save({\n",
    "    'model_state': mybing.state_dict(),\n",
    "    'optimizer_state': mybing.optimizer.state_dict(),\n",
    "    'epoch': mybing.total_epochs_trained\n",
    "    }, f\"model_large_{mybing.total_epochs_trained}.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint7 = torch.load(\"model_large_45.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "mybing.load_state_dict(checkpoint7['model_state'])\n",
    "mybing.optimizer.load_state_dict(checkpoint7['optimizer_state'])\n",
    "mybing.total_epochs_trained = checkpoint7['epoch']\n",
    "\n",
    "print(mybing.total_epochs_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / Global Epoch 46]\n",
      "    Train Loss:     1581.3161803483963\n",
      "    Test Accuracy:  0.8834\n",
      "    Best Test Acc:  0.8834\n",
      "\n",
      "[Epoch 1 / Global Epoch 47]\n",
      "    Train Loss:     1579.2013140916824\n",
      "    Test Accuracy:  0.8895\n",
      "    Best Test Acc:  0.8895\n",
      "\n",
      "[Epoch 2 / Global Epoch 48]\n",
      "    Train Loss:     1578.717133283615\n",
      "    Test Accuracy:  0.8855\n",
      "    Best Test Acc:  0.8895\n",
      "\n",
      "[Epoch 3 / Global Epoch 49]\n",
      "    Train Loss:     1578.2780284881592\n",
      "    Test Accuracy:  0.8866\n",
      "    Best Test Acc:  0.8895\n",
      "\n",
      "[Epoch 4 / Global Epoch 50]\n",
      "    Train Loss:     1576.4174890518188\n",
      "    Test Accuracy:  0.8902\n",
      "    Best Test Acc:  0.8902\n",
      "\n",
      "[Epoch 5 / Global Epoch 51]\n",
      "    Train Loss:     1574.875913977623\n",
      "    Test Accuracy:  0.8913\n",
      "    Best Test Acc:  0.8913\n",
      "\n",
      "[Epoch 6 / Global Epoch 52]\n",
      "    Train Loss:     1573.2555277347565\n",
      "    Test Accuracy:  0.8913\n",
      "    Best Test Acc:  0.8913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mybing.train(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    7\n",
    ")\n",
    "\n",
    "f = open(f\"model_large_{mybing.total_epochs_trained}.pt\", \"w\").close()\n",
    "torch.save({\n",
    "    'model_state': mybing.state_dict(),\n",
    "    'optimizer_state': mybing.optimizer.state_dict(),\n",
    "    'epoch': mybing.total_epochs_trained\n",
    "    }, f\"model_large_{mybing.total_epochs_trained}.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint8 = torch.load(\"model_large_52.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "mybing.load_state_dict(checkpoint8['model_state'])\n",
    "mybing.optimizer.load_state_dict(checkpoint8['optimizer_state'])\n",
    "mybing.total_epochs_trained = checkpoint8['epoch']\n",
    "\n",
    "print(mybing.total_epochs_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / Global Epoch 53]\n",
      "    Train Loss:     1573.055364727974\n",
      "    Test Accuracy:  0.8891\n",
      "    Best Test Acc:  0.8891\n",
      "\n",
      "[Epoch 1 / Global Epoch 54]\n",
      "    Train Loss:     1572.4587986469269\n",
      "    Test Accuracy:  0.8907\n",
      "    Best Test Acc:  0.8907\n",
      "\n",
      "[Epoch 2 / Global Epoch 55]\n",
      "    Train Loss:     1571.5949985980988\n",
      "    Test Accuracy:  0.8909\n",
      "    Best Test Acc:  0.8909\n",
      "\n",
      "[Epoch 3 / Global Epoch 56]\n",
      "    Train Loss:     1570.350787639618\n",
      "    Test Accuracy:  0.8883\n",
      "    Best Test Acc:  0.8909\n",
      "\n",
      "[Epoch 4 / Global Epoch 57]\n",
      "    Train Loss:     1568.5161921977997\n",
      "    Test Accuracy:  0.8923\n",
      "    Best Test Acc:  0.8923\n",
      "\n",
      "[Epoch 5 / Global Epoch 58]\n",
      "    Train Loss:     1567.1864584684372\n",
      "    Test Accuracy:  0.8931\n",
      "    Best Test Acc:  0.8931\n",
      "\n",
      "[Epoch 6 / Global Epoch 59]\n",
      "    Train Loss:     1568.2514601945877\n",
      "    Test Accuracy:  0.8895\n",
      "    Best Test Acc:  0.8931\n",
      "\n",
      "[Epoch 7 / Global Epoch 60]\n",
      "    Train Loss:     1566.8065421581268\n",
      "    Test Accuracy:  0.8887\n",
      "    Best Test Acc:  0.8931\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mybing.train(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    8\n",
    ")\n",
    "\n",
    "f = open(f\"model_large_{mybing.total_epochs_trained}.pt\", \"w\").close()\n",
    "torch.save({\n",
    "    'model_state': mybing.state_dict(),\n",
    "    'optimizer_state': mybing.optimizer.state_dict(),\n",
    "    'epoch': mybing.total_epochs_trained\n",
    "    }, f\"model_large_{mybing.total_epochs_trained}.pt\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78f5b707d86fd9281530b9fa2dbdbe1b33232c3b651a8e052360c651d4996094"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
